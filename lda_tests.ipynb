{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import *\n",
    "from svd import *\n",
    "from bert import *\n",
    "from document import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosfname = \"assets/cos_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selo/anaconda3/envs/ml-agents/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.decomposition.online_lda module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/selo/anaconda3/envs/ml-agents/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "l = SvdBaseline(cosfname)\n",
    "l.load(\"assets/log_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = l.lda\n",
    "lda_mat = l.doc_mat\n",
    "tf_idf = l.tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5, random_state=0,\n",
       "             tol=0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.fit(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assets/svd100']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(svd, \"assets/svd100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sparse matrices are not supported by this function. Perhaps one of the scipy.sparse.linalg functions would work instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-d9081d40864b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml-agents/lib/python3.6/site-packages/scipy/linalg/decomp_svd.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml-agents/lib/python3.6/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    239\u001b[0m                    \u001b[0;34m'Perhaps one of the scipy.sparse.linalg functions '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                    'would work instead.')\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misMaskedArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sparse matrices are not supported by this function. Perhaps one of the scipy.sparse.linalg functions would work instead."
     ]
    }
   ],
   "source": [
    "%time U, s, Vh = scipy.linalg.svd(l.tf_idf.todense(), full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191113, 100)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 135145)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = l.tf_idf[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "v1t = lda._unnormalized_transform(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(lda_mat, v1t)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.01567552, 0.00449813, 0.00645159, 0.20851149,\n",
       "       0.00509312, 0.00559347, 0.00748178, 0.00613798, 0.00675197,\n",
       "       0.00686474, 0.00507146, 0.00760364, 0.01838678, 0.00793569,\n",
       "       0.3186383 , 0.32265943, 0.0057386 , 0.00560834, 0.00585418,\n",
       "       0.00504656, 0.00509668, 0.01886648, 0.00685777, 0.0057807 ,\n",
       "       0.00966281, 0.0044818 , 0.00721908, 0.00855931, 0.00461534,\n",
       "       0.00566772, 0.00412278, 0.00561873, 0.00864036, 0.00551905,\n",
       "       0.0046067 , 0.00518043, 0.00879181, 0.00657389, 0.00626442,\n",
       "       0.00644452, 0.00626587, 0.9361829 , 0.00691375, 0.00678517,\n",
       "       0.00517388, 0.00490478, 0.0051894 , 0.00565587, 0.00514543,\n",
       "       0.00745998, 0.13952685, 0.01305496, 0.01186419, 0.01445774,\n",
       "       0.01445774, 0.0174241 , 0.01445774, 0.00656696, 0.00661439,\n",
       "       0.0044571 , 0.00625639, 0.9280075 , 0.56570409, 0.00759364,\n",
       "       0.00567971, 0.00802887, 0.00611708, 0.00676262, 0.00594707,\n",
       "       0.00611329, 0.00530819, 0.00601807, 0.00539888, 0.00576477,\n",
       "       0.00510294, 0.00442955, 0.00729201, 0.00487781, 0.00461452,\n",
       "       0.32756572, 0.00521316, 0.00510126, 0.00409124, 0.00713732,\n",
       "       0.00417943, 0.3611448 , 0.25561674, 0.00620536, 0.00653154,\n",
       "       0.04939133, 0.00548842, 0.00999361, 0.03639246, 0.00521234,\n",
       "       0.08456251, 0.00503575, 0.00701466, 0.00505873, 0.00432124])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0, 165772,  83867,  13785, 185476, 139989,   8937,  80218,\n",
       "        62228,    691,  41436,   4674,  36491, 170305, 140145,  19765,\n",
       "        58721, 162867, 178857, 138433, 139324, 135893,  67509, 124395,\n",
       "        13338, 181905, 149203, 158465,  45176, 190970,   3071,  81281,\n",
       "        55112,  69092, 143563, 137821, 150342,  86073, 159954, 136052,\n",
       "       158765, 154880,  14421,  13335,  83580,  12460, 169954, 180335,\n",
       "         1799, 187891, 157754,   1840, 146264, 148019, 147213,  78903,\n",
       "         2992, 154391,  79634, 177700,  26512, 157687,  49091,   4454,\n",
       "       153495, 150646, 147624, 132834, 165057, 159642, 172801, 181897,\n",
       "       142627, 143330,  87587, 149550, 144186, 132582,   2166, 189162,\n",
       "         6478, 153672, 154560, 148319, 155518, 171902, 157146,  12031,\n",
       "       133193,   2134,  87551,  84290, 149648,   1117,  16097, 154108,\n",
       "       184913, 187279,   6867, 183885])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-sim).argsort()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 4.8983968 , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 1.72322241, 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "       0.01      , 0.01      , 0.01      , 0.66819851, 0.01      ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_mat[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 4.8983968 , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 1.72322241, 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.01      , 0.01      ,\n",
       "        0.01      , 0.01      , 0.01      , 0.66819851, 0.01      ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99200399]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v1t, lda_mat[165772, :].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnormalized_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = load_topics(retrieve=\"even\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['resect', 'techniqu', 'complic', 'surgic', 'oper', 'postop', 'group', 'patient', 'surgeri', 'laparoscop']\n",
      "--------------------------------------------------\n",
      "Topic 1:\n",
      "['alert', 'silenc', 'overdos', 'covid', 'compassion', 'abus', 'remdesivir', 'sirna', 'rnai', 'opioid']\n",
      "--------------------------------------------------\n",
      "Topic 2:\n",
      "['commun', 'polici', 'diseas', 'social', 'research', 'global', 'covid', 'pandem', 'public', 'health']\n",
      "--------------------------------------------------\n",
      "Topic 3:\n",
      "['cessat', 'vape', 'nicotin', 'tracheotomi', 'covid', 'tobacco', 'cigarett', 'smoker', 'thyroid', 'smoke']\n",
      "--------------------------------------------------\n",
      "Topic 4:\n",
      "['hypertens', 'enzym', 'blocker', 'acei', 'convert', 'ace', 'renin', 'inhibitor', 'arb', 'angiotensin']\n",
      "--------------------------------------------------\n",
      "Topic 5:\n",
      "['altitud', 'superspread', 'regard', 'repli', 'respons', 'covid', 'al', 'et', 'editor', 'letter']\n",
      "--------------------------------------------------\n",
      "Topic 6:\n",
      "['recommend', 'healthcar', 'health', 'practic', 'hospit', 'manag', 'pandem', 'patient', 'care', 'covid']\n",
      "--------------------------------------------------\n",
      "Topic 7:\n",
      "['new', 'research', 'infecti', 'human', 'therapeut', 'pathogen', 'diseas', 'immun', 'develop', 'vaccin']\n",
      "--------------------------------------------------\n",
      "Topic 8:\n",
      "['unknown', 'exacerb', 'america', 'asthmat', 'latin', 'brazil', 'covid', 'allerg', 'allergi', 'asthma']\n",
      "--------------------------------------------------\n",
      "Topic 9:\n",
      "['ultraviolet', 'ubiquitin', 'parkinson', 'plpro', 'dub', 'covid', 'wear', 'face', 'respir', 'mask']\n",
      "--------------------------------------------------\n",
      "Topic 10:\n",
      "['learn', 'propos', 'algorithm', 'data', 'detect', 'base', 'method', 'network', 'use', 'model']\n",
      "--------------------------------------------------\n",
      "Topic 11:\n",
      "['sleev', 'bypass', 'gastric', 'lsg', 'bmi', 'glucos', 'weight', 'bariatr', 'obes', 'diabet']\n",
      "--------------------------------------------------\n",
      "Topic 12:\n",
      "['talk', 'love', 'abo', 'autism', 'aftermath', 'disast', 'covid', 'fdg', 'ethic', 'pet']\n",
      "--------------------------------------------------\n",
      "Topic 13:\n",
      "['princess', 'diamond', 'medicin', 'portug', 'nuclear', 'psychiatr', 'covid', 'cruis', 'ship', 'back']\n",
      "--------------------------------------------------\n",
      "Topic 14:\n",
      "['resid', 'medic', 'perspect', 'crisi', 'student', 'nurs', 'editori', 'educ', 'pandem', 'covid']\n",
      "--------------------------------------------------\n",
      "Topic 15:\n",
      "['lo', 'con', 'del', 'pandemia', 'covid', 'por', 'el', 'en', 'la', 'de']\n",
      "--------------------------------------------------\n",
      "Topic 16:\n",
      "['brachytherapi', 'sichuan', 'tokyo', 'transcathet', 'aortic', 'antihypertens', 'prf', 'valv', 'agenda', 'pseudoknot']\n",
      "--------------------------------------------------\n",
      "Topic 17:\n",
      "['hepatocellular', 'rf', 'carcinoma', 'liver', 'hepat', 'hcc', 'tumor', 'radiofrequ', 'rfa', 'ablat']\n",
      "--------------------------------------------------\n",
      "Topic 18:\n",
      "['workshop', 'isbn', 'bereav', 'covid', 'fulmin', 'edit', 'echocardiographi', 'myocard', 'blood', 'transfus']\n",
      "--------------------------------------------------\n",
      "Topic 19:\n",
      "['ageism', 'ect', 'sci', 'morocco', 'watch', 'autoimmun', 'happen', 'highlight', 'symposium', 'issu']\n",
      "--------------------------------------------------\n",
      "Topic 20:\n",
      "['zinc', 'enterocol', 'covid', 'necrot', 'oh', 'revisit', 'defici', 'nec', 'supplement', 'vitamin']\n",
      "--------------------------------------------------\n",
      "Topic 21:\n",
      "['grave', 'neglect', 'camp', 'ncd', 'bangladesh', 'immigr', 'tropic', 'refuge', 'pakistan', 'burn']\n",
      "--------------------------------------------------\n",
      "Topic 22:\n",
      "['greec', 'armi', 'dystrophi', 'tmd', 'idv', 'bulletin', 'vl', 'afghanistan', 'calm', 'certif']\n",
      "--------------------------------------------------\n",
      "Topic 23:\n",
      "['sevofluran', 'exercis', 'anesthet', 'sleep', 'bi', 'sedat', 'anaesthesia', 'propofol', 'anesthesia', 'pain']\n",
      "--------------------------------------------------\n",
      "Topic 24:\n",
      "['chikv', 'chikungunya', 'mosquito', 'enceph', 'denv', 'fever', 'zikv', 'zika', 'malaria', 'dengu']\n",
      "--------------------------------------------------\n",
      "Topic 25:\n",
      "['tear', 'corneal', 'conjunct', 'conjunctiv', 'covid', 'ophthalmologist', 'ophthalm', 'ophthalmolog', 'ocular', 'eye']\n",
      "--------------------------------------------------\n",
      "Topic 26:\n",
      "['puppi', 'distemp', 'madrid', 'rabi', 'forum', 'parvoviru', 'ccov', 'cpv', 'dog', 'canin']\n",
      "--------------------------------------------------\n",
      "Topic 27:\n",
      "['healthcar', 'care', 'anxieti', 'social', 'psycholog', 'worker', 'pandem', 'mental', 'health', 'covid']\n",
      "--------------------------------------------------\n",
      "Topic 28:\n",
      "['cold', 'let', 'lopinavir', 'ritonavir', 'turkey', 'covid', 'forget', 'nh', 'iran', 'say']\n",
      "--------------------------------------------------\n",
      "Topic 29:\n",
      "['covid', 'intellig', 'pdc', 'cr', 'artifici', 'ep', 'radiat', 'cq', 'tocilizumab', 'oncolog']\n",
      "--------------------------------------------------\n",
      "Topic 30:\n",
      "['igg', 'covid', 'rt', 'detect', 'pcr', 'assay', 'antibodi', 'test', 'cov', 'sar']\n",
      "--------------------------------------------------\n",
      "Topic 31:\n",
      "['occlus', 'cerebr', 'treatment', 'endovascular', 'embol', 'stent', 'aneurysm', 'arteri', 'stroke', 'patient']\n",
      "--------------------------------------------------\n",
      "Topic 32:\n",
      "['wall', 'prolaps', 'heal', 'fixat', 'implant', 'inguin', 'wound', 'repair', 'hernia', 'mesh']\n",
      "--------------------------------------------------\n",
      "Topic 33:\n",
      "['york', 'radiolog', 'pediatr', 'azithromycin', 'sclerosi', 'know', 'hcq', 'chloroquin', 'covid', 'hydroxychloroquin']\n",
      "--------------------------------------------------\n",
      "Topic 34:\n",
      "['justic', 'ontolog', 'gastrointestin', 'reproduct', 'fake', 'semant', 'offlin', 'covid', 'sexual', 'endoscopi']\n",
      "--------------------------------------------------\n",
      "Topic 35:\n",
      "['express', 'membran', 'replic', 'viral', 'bind', 'structur', 'viru', 'rna', 'cell', 'protein']\n",
      "--------------------------------------------------\n",
      "Topic 36:\n",
      "['len', 'matter', 'gondii', 'get', 'corrigendum', 'covid', 'stemi', 'infarct', 'st', 'myocardi']\n",
      "--------------------------------------------------\n",
      "Topic 37:\n",
      "['failur', 'cardiopulmonari', 'membran', 'oxygen', 'resuscit', 'covid', 'heart', 'extracorpor', 'ecmo', 'cardiac']\n",
      "--------------------------------------------------\n",
      "Topic 38:\n",
      "['angel', 'hypersensit', 'covid', 'tf', 'uc', 'syndrom', 'rrt', 'gb', 'barré', 'guillain']\n",
      "--------------------------------------------------\n",
      "Topic 39:\n",
      "['btv', 'urticaria', 'ventricular', 'road', 'right', 'journey', 'eu', 'interview', 'covid', 'audio']\n",
      "--------------------------------------------------\n",
      "Topic 40:\n",
      "['encephalopathi', 'reconsid', 'rituximab', 'move', 'cf', 'forward', 'covid', 'look', 'neurolog', 'comment']\n",
      "--------------------------------------------------\n",
      "Topic 41:\n",
      "['patient', 'viru', 'detect', 'viral', 'pneumonia', 'virus', 'infect', 'children', 'influenza', 'respiratori']\n",
      "--------------------------------------------------\n",
      "Topic 42:\n",
      "['invis', 'het', 'een', 'chilblain', 'violenc', 'de', 'van', 'covid', 'author', 'repli']\n",
      "--------------------------------------------------\n",
      "Topic 43:\n",
      "['cyclosporin', 'crt', 'tapp', 'quercetin', 'eat', 'tell', 'extraperiton', 'inguin', 'tep', 'stori']\n",
      "--------------------------------------------------\n",
      "Topic 44:\n",
      "['syndrom', 'coronaviru', 'infect', 'cardiovascular', 'cov', 'sar', 'sever', 'patient', 'diseas', 'covid']\n",
      "--------------------------------------------------\n",
      "Topic 45:\n",
      "['viru', 'activ', 'ifn', 'induc', 'mice', 'respons', 'express', 'immun', 'infect', 'cell']\n",
      "--------------------------------------------------\n",
      "Topic 46:\n",
      "['symptom', 'pneumonia', 'hospit', 'diseas', 'sever', 'clinic', 'case', 'ct', 'covid', 'patient']\n",
      "--------------------------------------------------\n",
      "Topic 47:\n",
      "['oligosaccharid', 'autophagosom', 'chaperon', 'lectin', 'sign', 'upr', 'coil', 'scfv', 'ntd', 'dc']\n",
      "--------------------------------------------------\n",
      "Topic 48:\n",
      "['virucid', 'internet', 'legaci', 'ocd', 'pvp', 'fox', 'obsess', 'pap', 'compuls', 'acc']\n",
      "--------------------------------------------------\n",
      "Topic 49:\n",
      "['genet', 'gene', 'strain', 'speci', 'virus', 'human', 'viru', 'bat', 'genom', 'sequenc']\n",
      "--------------------------------------------------\n",
      "Topic 50:\n",
      "['iron', 'neuroendocrin', 'id', 'label', 'tumor', 'uptak', 'foal', 'spect', 'imag', 'tc']\n",
      "--------------------------------------------------\n",
      "Topic 51:\n",
      "['drone', 'nr', 'tka', 'shift', 'hip', 'hemophagocyt', 'octob', 'knee', 'paradigm', 'arthroplasti']\n",
      "--------------------------------------------------\n",
      "Topic 52:\n",
      "['someth', 'ehr', 'npc', 'uveiti', 'telerehabilit', 'cta', 'leukaemia', 'aki', 'kong', 'hong']\n",
      "--------------------------------------------------\n",
      "Topic 53:\n",
      "['birth', 'deliveri', 'mother', 'covid', 'infant', 'matern', 'neonat', 'women', 'pregnanc', 'pregnant']\n",
      "--------------------------------------------------\n",
      "Topic 54:\n",
      "['rvp', 'american', 'caution', 'confer', 'sport', 'european', 'societi', 'annual', 'meet', 'abstract']\n",
      "--------------------------------------------------\n",
      "Topic 55:\n",
      "['covid', 'sui', 'report', 'erk', 'pmo', 'nail', 'aedt', 'australian', 'ibuprofen', 'australia']\n",
      "--------------------------------------------------\n",
      "Topic 56:\n",
      "['droplet', 'airborn', 'mask', 'water', 'contamin', 'pollut', 'temperatur', 'transmiss', 'aerosol', 'air']\n",
      "--------------------------------------------------\n",
      "Topic 57:\n",
      "['casei', 'sport', 'salud', 'lactobacillu', 'elit', 'trump', 'tuberculosi', 'sickl', 'athlet', 'tb']\n",
      "--------------------------------------------------\n",
      "Topic 58:\n",
      "['democraci', 'prp', 'ltc', 'uncertain', 'prion', 'stigma', 'covid', 'anesthesiolog', 'hear', 'gastrointestin']\n",
      "--------------------------------------------------\n",
      "Topic 59:\n",
      "['programm', 'mump', 'ecr', 'mv', 'rat', 'mp', 'depart', 'measl', 'error', 'news']\n",
      "--------------------------------------------------\n",
      "Topic 60:\n",
      "['dark', 'tourism', 'rhesu', 'monkey', 'trace', 'hrsv', 'app', 'ahead', 'macaqu', 'think']\n",
      "--------------------------------------------------\n",
      "Topic 61:\n",
      "['im', 'bei', 'mit', 'ein', 'für', 'corona', 'von', 'die', 'und', 'der']\n",
      "--------------------------------------------------\n",
      "Topic 62:\n",
      "['hemodialysi', 'adren', 'adrenalectomi', 'otolaryngologist', 'covid', 'ppe', 'shield', 'equip', 'protect', 'person']\n",
      "--------------------------------------------------\n",
      "Topic 63:\n",
      "['struggl', 'biochemistri', 'parastom', 'ecov', 'stethoscop', 'biobank', 'prv', 'bvdv', 'equin', 'hors']\n",
      "--------------------------------------------------\n",
      "Topic 64:\n",
      "['piec', 'neurologist', 'new', 'puzzl', 'normal', 'ipc', 'miss', 'dvt', 'covid', 'era']\n",
      "--------------------------------------------------\n",
      "Topic 65:\n",
      "['biolog', 'bowel', 'covid', 'psoriasi', 'rheumatolog', 'subject', 'content', 'rheumat', 'index', 'volum']\n",
      "--------------------------------------------------\n",
      "Topic 66:\n",
      "['event', 'española', 'gii', 'hhv', 'aspergillosi', 'norovirus', 'nov', 'calendar', 'retin', 'noroviru']\n",
      "--------------------------------------------------\n",
      "Topic 67:\n",
      "['intensivist', 'ebolaviru', 'saa', 'filoviru', 'stop', 'evd', 'ebov', 'congress', 'gp', 'ebola']\n",
      "--------------------------------------------------\n",
      "Topic 68:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['covid', 'nucleolu', 'diseas', 'surveil', 'line', 'erythematosu', 'infecti', 'lupu', 'front', 'updat']\n",
      "--------------------------------------------------\n",
      "Topic 69:\n",
      "['inflammatori', 'mesenchym', 'multisystem', 'exosom', 'teledermatolog', 'geriatr', 'covid', 'orthopaed', 'msc', 'kawasaki']\n",
      "--------------------------------------------------\n",
      "Topic 70:\n",
      "['covid', 'target', 'proteas', 'activ', 'inhibitor', 'compound', 'antivir', 'cov', 'sar', 'drug']\n",
      "--------------------------------------------------\n",
      "Topic 71:\n",
      "['northern', 'india', 'prepared', 'pandem', 'africa', 'hiv', 'learn', 'itali', 'covid', 'lesson']\n",
      "--------------------------------------------------\n",
      "Topic 72:\n",
      "['bovin', 'viru', 'de', 'porcin', 'pig', 'felin', 'calv', 'pedv', 'diarrhea', 'cat']\n",
      "--------------------------------------------------\n",
      "Topic 73:\n",
      "['second', 'link', 'correct', 'top', 'manifest', 'melatonin', 'amend', 'publish', 'paper', 'cutan']\n",
      "--------------------------------------------------\n",
      "Topic 74:\n",
      "['varicella', 'simplex', 'uri', 'zoster', 'corticosteroid', 'herp', 'ebv', 'hsv', 'race', 'cmv']\n",
      "--------------------------------------------------\n",
      "Topic 75:\n",
      "['fibrosi', 'integr', 'cystic', 'scientif', 'biosensor', 'tweet', 'tradit', 'tcm', 'chines', 'medicin']\n",
      "--------------------------------------------------\n",
      "Topic 76:\n",
      "['black', 'digit', 'racial', 'pandem', 'dispar', 'paediatr', 'ethnic', 'telemedicin', 'covid', 'dermatolog']\n",
      "--------------------------------------------------\n",
      "Topic 77:\n",
      "['ckd', 'lt', 'brace', 'covid', 'lpv', 'friend', 'foe', 'big', 'taiwan', 'tuberculosi']\n",
      "--------------------------------------------------\n",
      "Topic 78:\n",
      "['evid', 'patient', 'clinic', 'analysi', 'search', 'meta', 'systemat', 'studi', 'review', 'trial']\n",
      "--------------------------------------------------\n",
      "Topic 79:\n",
      "['fundopl', 'oil', 'pseudomona', 'resist', 'kingdom', 'methicillin', 'aeruginosa', 'staphylococcu', 'mrsa', 'aureu']\n",
      "--------------------------------------------------\n",
      "Topic 80:\n",
      "['lion', 'hd', 'igi', 'heparin', 'cheetah', 'statin', 'virolog', 'cdv', 'fcv', 'nutrit']\n",
      "--------------------------------------------------\n",
      "Topic 81:\n",
      "['atyp', 'psoriat', 'homeless', 'cutan', 'surg', 'rash', 'amidst', 'covid', 'next', 'skin']\n",
      "--------------------------------------------------\n",
      "Topic 82:\n",
      "['adr', 'laryngectomi', 'michael', 'panic', 'covid', 'ir', 'bioterror', 'page', 'realli', 'go']\n",
      "--------------------------------------------------\n",
      "Topic 83:\n",
      "['macroeconom', 'fu', 'congo', 'phc', 'physiotherapi', 'mood', 'ehealth', 'cb', 'cchf', 'nsaid']\n",
      "--------------------------------------------------\n",
      "Topic 84:\n",
      "['ss', 'inhaltsverzeichni', 'vignett', 'covid', 'adem', 'edg', 'nervou', 'iranian', 'moral', 'pancreat']\n",
      "--------------------------------------------------\n",
      "Topic 85:\n",
      "['mechan', 'tube', 'tracheal', 'covid', 'patient', 'pressur', 'tracheostomi', 'airway', 'intub', 'ventil']\n",
      "--------------------------------------------------\n",
      "Topic 86:\n",
      "['harm', 'dysphagia', 'flatten', 'probiot', 'tackl', 'covid', 'news', 'prison', 'rehabilit', 'brief']\n",
      "--------------------------------------------------\n",
      "Topic 87:\n",
      "['diseas', 'countri', 'spread', 'outbreak', 'infect', 'model', 'china', 'epidem', 'case', 'covid']\n",
      "--------------------------------------------------\n",
      "Topic 88:\n",
      "['idiopath', 'mc', 'rm', 'lynx', 'youtub', 'ae', 'fl', 'ipf', 'tabl', 'vol']\n",
      "--------------------------------------------------\n",
      "Topic 89:\n",
      "['lym', 'neuroradiologist', 'hai', 'sr', 'survivor', 'bpd', 'croup', 'lagb', 'immunolog', 'rhinosinus']\n",
      "--------------------------------------------------\n",
      "Topic 90:\n",
      "['amr', 'covid', 'deutschen', 'hidden', 'antimicrobi', 'der', 'inequ', 'plagu', 'dentistri', 'mitteilungen']\n",
      "--------------------------------------------------\n",
      "Topic 91:\n",
      "['scrambl', 'pneumocysti', 'asd', 'hs', 'phev', 'lab', 'quasispeci', 'phe', 'pituitari', 'fmdv']\n",
      "--------------------------------------------------\n",
      "Topic 92:\n",
      "['colorect', 'surgeri', 'chemotherapi', 'lung', 'pandem', 'patient', 'covid', 'radiotherapi', 'breast', 'cancer']\n",
      "--------------------------------------------------\n",
      "Topic 93:\n",
      "['vision', 'bergamo', 'mass', 'loss', 'gather', 'pilgrim', 'tast', 'sleep', 'smell', 'hajj']\n",
      "--------------------------------------------------\n",
      "Topic 94:\n",
      "['hematopoiet', 'stem', 'immunosuppress', 'lung', 'donor', 'covid', 'kidney', 'liver', 'recipi', 'transplant']\n",
      "--------------------------------------------------\n",
      "Topic 95:\n",
      "['graphen', 'di', 'articl', 'http', 'org', 'game', 'doi', 'ferret', 'lancet', 'correct']\n",
      "--------------------------------------------------\n",
      "Topic 96:\n",
      "['segmentectomi', 'splenic', 'clozapin', 'spine', 'spinal', 'covid', 'splenectomi', 'cardiolog', 'beyond', 'telehealth']\n",
      "--------------------------------------------------\n",
      "Topic 97:\n",
      "['digest', 'maxillofaci', 'periton', 'pd', 'trauma', 'collater', 'italian', 'covid', 'dialysi', 'oral']\n",
      "--------------------------------------------------\n",
      "Topic 98:\n",
      "['sever', 'sar', 'acut', 'coronaviru', 'middl', 'east', 'cov', 'respiratori', 'syndrom', 'mer']\n",
      "--------------------------------------------------\n",
      "Topic 99:\n",
      "['career', 'paus', 'jail', 'tr', 'covid', 'dysmenorrhea', 'keyword', 'legal', 'myeloma', 'rethink']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "id2word = {a:b for b, a in l.word2id.items()}\n",
    "for i, topic in enumerate(l.lda.components_):\n",
    "    print(\"Topic {}:\".format(i))\n",
    "    print([id2word[i] for i in topic.argsort()[-10:]])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 191113) (100, 191113) (100, 191113)\n",
      "0 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 / 25\n",
      "(100, 191113) (100, 191113) (100, 191113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 / 25\n"
     ]
    }
   ],
   "source": [
    "evals = eval_topics(topics, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selo/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (1,4,5,6,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d5afadfe7750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrec_ir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertRanker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"assets/tfidf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/semesters/m1/493/term_prj/trec_covid/bert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fname_base)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gsarti/covidbert-nli\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute 'load'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
